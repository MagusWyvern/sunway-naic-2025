{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["# **National AI Competition - Technical Track**\n","\n","This document provides guidance on how to properly submit your Kuih Classification project. Your submission will be tested using an automated script similar to the example provided, so it's essential that you follow these guidelines precisely.\n","\n","## **Required Files for Submission**\n","\n","1. Machine Learning Model\n","\n","\n","*   Your Model Weights (Ex: ``keras_model.h5``)\n","*   Class labels file (if applicable)\n","\n","2. Testing Script\n","\n","*   A Google Colab Notebook that can load and test your model.\n","*   The script must work with the predefined test dataset path\n","\n","## **Example Test Dataset**\n","\n","An example of folder of test images will be located in this Google Dirve:\n","https://drive.google.com/drive/folders/1NzCoYjsMnTTPf3lWCfnylG8IF_VQenkM?usp=sharing\n","\n","Be sure to add a shortcut to your drive for the testing. Your script must be able to access and process images in this directory without modification.\n","\n","\n","## **Example Testing Script**\n","\n","Below is an example testing script that utilizes model weights exported from Teachable Machine.\n","\n","\n"],"metadata":{"id":"nsL1OpizWead"}},{"cell_type":"markdown","source":["### 1. Setting Up the Environment\n","\n","This section, we install the necessary libraries. For Teachable Machine Models, we specifically install TensorFlow 2.12.0; However, for your own models, installing the latest version of TensorFlow might be better."],"metadata":{"id":"nR4lrolJX1Gf"}},{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":0},"id":"MctD6Pe1MRtT","executionInfo":{"status":"ok","timestamp":1748052331315,"user_tz":-480,"elapsed":92380,"user":{"displayName":"Jay Yen Lim","userId":"02744417412835953839"}},"outputId":"4b28c8dc-45ed-4e13-9c95-22d7c1943df5"},"outputs":[{"output_type":"stream","name":"stdout","text":["Found existing installation: numpy 2.0.2\n","Uninstalling numpy-2.0.2:\n","  Successfully uninstalled numpy-2.0.2\n","Found existing installation: pandas 2.2.2\n","Uninstalling pandas-2.2.2:\n","  Successfully uninstalled pandas-2.2.2\n","Found existing installation: tensorflow 2.18.0\n","Uninstalling tensorflow-2.18.0:\n","  Successfully uninstalled tensorflow-2.18.0\n","Collecting tensorflow==2.12.0\n","  Downloading tensorflow-2.12.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.4 kB)\n","Collecting numpy==1.23.5\n","  Downloading numpy-1.23.5-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (2.3 kB)\n","Collecting pandas==1.5.3\n","  Downloading pandas-1.5.3-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (11 kB)\n","Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.12.0) (1.4.0)\n","Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.12.0) (1.6.3)\n","Requirement already satisfied: flatbuffers>=2.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.12.0) (25.2.10)\n","Collecting gast<=0.4.0,>=0.2.1 (from tensorflow==2.12.0)\n","  Downloading gast-0.4.0-py3-none-any.whl.metadata (1.1 kB)\n","Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.12.0) (0.2.0)\n","Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.12.0) (1.71.0)\n","Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.12.0) (3.13.0)\n","Requirement already satisfied: jax>=0.3.15 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.12.0) (0.5.2)\n","Collecting keras<2.13,>=2.12.0 (from tensorflow==2.12.0)\n","  Downloading keras-2.12.0-py2.py3-none-any.whl.metadata (1.4 kB)\n","Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.12.0) (18.1.1)\n","Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.12.0) (3.4.0)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.12.0) (24.2)\n","Collecting protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 (from tensorflow==2.12.0)\n","  Downloading protobuf-4.25.7-cp37-abi3-manylinux2014_x86_64.whl.metadata (541 bytes)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.12.0) (75.2.0)\n","Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.12.0) (1.17.0)\n","Collecting tensorboard<2.13,>=2.12 (from tensorflow==2.12.0)\n","  Downloading tensorboard-2.12.3-py3-none-any.whl.metadata (1.8 kB)\n","Collecting tensorflow-estimator<2.13,>=2.12.0 (from tensorflow==2.12.0)\n","  Downloading tensorflow_estimator-2.12.0-py2.py3-none-any.whl.metadata (1.3 kB)\n","Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.12.0) (3.1.0)\n","Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.12.0) (4.13.2)\n","Collecting wrapt<1.15,>=1.11.0 (from tensorflow==2.12.0)\n","  Downloading wrapt-1.14.1-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.7 kB)\n","Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.12.0) (0.37.1)\n","Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.11/dist-packages (from pandas==1.5.3) (2.9.0.post0)\n","Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas==1.5.3) (2025.2)\n","Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from astunparse>=1.6.0->tensorflow==2.12.0) (0.45.1)\n","Requirement already satisfied: jaxlib<=0.5.2,>=0.5.1 in /usr/local/lib/python3.11/dist-packages (from jax>=0.3.15->tensorflow==2.12.0) (0.5.1)\n","Requirement already satisfied: ml_dtypes>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from jax>=0.3.15->tensorflow==2.12.0) (0.4.1)\n","INFO: pip is looking at multiple versions of jax to determine which version is compatible with other requirements. This could take a while.\n","Collecting jax>=0.3.15 (from tensorflow==2.12.0)\n","  Downloading jax-0.6.1-py3-none-any.whl.metadata (13 kB)\n","Collecting jaxlib<=0.6.1,>=0.6.1 (from jax>=0.3.15->tensorflow==2.12.0)\n","  Downloading jaxlib-0.6.1-cp311-cp311-manylinux2014_x86_64.whl.metadata (1.2 kB)\n","Collecting ml_dtypes>=0.5.0 (from jax>=0.3.15->tensorflow==2.12.0)\n","  Downloading ml_dtypes-0.5.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (21 kB)\n","Collecting jax>=0.3.15 (from tensorflow==2.12.0)\n","  Downloading jax-0.6.0-py3-none-any.whl.metadata (22 kB)\n","Collecting jaxlib<=0.6.0,>=0.6.0 (from jax>=0.3.15->tensorflow==2.12.0)\n","  Downloading jaxlib-0.6.0-cp311-cp311-manylinux2014_x86_64.whl.metadata (1.2 kB)\n","Collecting jax>=0.3.15 (from tensorflow==2.12.0)\n","  Downloading jax-0.5.3-py3-none-any.whl.metadata (22 kB)\n","Collecting jaxlib<=0.5.3,>=0.5.3 (from jax>=0.3.15->tensorflow==2.12.0)\n","  Downloading jaxlib-0.5.3-cp311-cp311-manylinux2014_x86_64.whl.metadata (1.2 kB)\n","Collecting jax>=0.3.15 (from tensorflow==2.12.0)\n","  Downloading jax-0.5.1-py3-none-any.whl.metadata (22 kB)\n","  Downloading jax-0.5.0-py3-none-any.whl.metadata (22 kB)\n","Collecting jaxlib<=0.5.0,>=0.5.0 (from jax>=0.3.15->tensorflow==2.12.0)\n","  Downloading jaxlib-0.5.0-cp311-cp311-manylinux2014_x86_64.whl.metadata (978 bytes)\n","Collecting jax>=0.3.15 (from tensorflow==2.12.0)\n","  Downloading jax-0.4.38-py3-none-any.whl.metadata (22 kB)\n","Collecting jaxlib<=0.4.38,>=0.4.38 (from jax>=0.3.15->tensorflow==2.12.0)\n","  Downloading jaxlib-0.4.38-cp311-cp311-manylinux2014_x86_64.whl.metadata (1.0 kB)\n","Collecting jax>=0.3.15 (from tensorflow==2.12.0)\n","  Downloading jax-0.4.37-py3-none-any.whl.metadata (22 kB)\n","Collecting jaxlib<=0.4.37,>=0.4.36 (from jax>=0.3.15->tensorflow==2.12.0)\n","  Downloading jaxlib-0.4.36-cp311-cp311-manylinux2014_x86_64.whl.metadata (1.0 kB)\n","INFO: pip is still looking at multiple versions of jax to determine which version is compatible with other requirements. This could take a while.\n","Collecting jax>=0.3.15 (from tensorflow==2.12.0)\n","  Downloading jax-0.4.36-py3-none-any.whl.metadata (22 kB)\n","  Downloading jax-0.4.35-py3-none-any.whl.metadata (22 kB)\n","Collecting jaxlib<=0.4.35,>=0.4.34 (from jax>=0.3.15->tensorflow==2.12.0)\n","  Downloading jaxlib-0.4.35-cp311-cp311-manylinux2014_x86_64.whl.metadata (983 bytes)\n","Collecting jax>=0.3.15 (from tensorflow==2.12.0)\n","  Downloading jax-0.4.34-py3-none-any.whl.metadata (22 kB)\n","Collecting jaxlib<=0.4.34,>=0.4.34 (from jax>=0.3.15->tensorflow==2.12.0)\n","  Downloading jaxlib-0.4.34-cp311-cp311-manylinux2014_x86_64.whl.metadata (983 bytes)\n","Collecting jax>=0.3.15 (from tensorflow==2.12.0)\n","  Downloading jax-0.4.33-py3-none-any.whl.metadata (22 kB)\n","Collecting jaxlib<=0.4.33,>=0.4.33 (from jax>=0.3.15->tensorflow==2.12.0)\n","  Downloading jaxlib-0.4.33-cp311-cp311-manylinux2014_x86_64.whl.metadata (983 bytes)\n","Collecting jax>=0.3.15 (from tensorflow==2.12.0)\n","  Downloading jax-0.4.31-py3-none-any.whl.metadata (22 kB)\n","Collecting jaxlib<=0.4.31,>=0.4.30 (from jax>=0.3.15->tensorflow==2.12.0)\n","  Downloading jaxlib-0.4.31-cp311-cp311-manylinux2014_x86_64.whl.metadata (983 bytes)\n","INFO: This is taking longer than usual. You might need to provide the dependency resolver with stricter constraints to reduce runtime. See https://pip.pypa.io/warnings/backtracking for guidance. If you want to abort this run, press Ctrl + C.\n","Collecting jax>=0.3.15 (from tensorflow==2.12.0)\n","  Downloading jax-0.4.30-py3-none-any.whl.metadata (22 kB)\n","Collecting jaxlib<=0.4.30,>=0.4.27 (from jax>=0.3.15->tensorflow==2.12.0)\n","  Downloading jaxlib-0.4.30-cp311-cp311-manylinux2014_x86_64.whl.metadata (1.0 kB)\n","Requirement already satisfied: scipy>=1.9 in /usr/local/lib/python3.11/dist-packages (from jax>=0.3.15->tensorflow==2.12.0) (1.15.3)\n","Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.13,>=2.12->tensorflow==2.12.0) (2.38.0)\n","Collecting google-auth-oauthlib<1.1,>=0.5 (from tensorboard<2.13,>=2.12->tensorflow==2.12.0)\n","  Downloading google_auth_oauthlib-1.0.0-py2.py3-none-any.whl.metadata (2.7 kB)\n","Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.13,>=2.12->tensorflow==2.12.0) (3.8)\n","Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.13,>=2.12->tensorflow==2.12.0) (2.32.3)\n","Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.13,>=2.12->tensorflow==2.12.0) (0.7.2)\n","Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.13,>=2.12->tensorflow==2.12.0) (3.1.3)\n","Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow==2.12.0) (5.5.2)\n","Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.11/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow==2.12.0) (0.4.2)\n","Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.11/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow==2.12.0) (4.9.1)\n","Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from google-auth-oauthlib<1.1,>=0.5->tensorboard<2.13,>=2.12->tensorflow==2.12.0) (2.0.0)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorboard<2.13,>=2.12->tensorflow==2.12.0) (3.4.2)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorboard<2.13,>=2.12->tensorflow==2.12.0) (3.10)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorboard<2.13,>=2.12->tensorflow==2.12.0) (2.4.0)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorboard<2.13,>=2.12->tensorflow==2.12.0) (2025.4.26)\n","Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.11/dist-packages (from werkzeug>=1.0.1->tensorboard<2.13,>=2.12->tensorflow==2.12.0) (3.0.2)\n","Requirement already satisfied: pyasn1<0.7.0,>=0.6.1 in /usr/local/lib/python3.11/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow==2.12.0) (0.6.1)\n","Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.11/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<1.1,>=0.5->tensorboard<2.13,>=2.12->tensorflow==2.12.0) (3.2.2)\n","Downloading tensorflow-2.12.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (586.0 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m586.0/586.0 MB\u001b[0m \u001b[31m241.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading numpy-1.23.5-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (17.1 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m17.1/17.1 MB\u001b[0m \u001b[31m110.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading pandas-1.5.3-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (12.0 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.0/12.0 MB\u001b[0m \u001b[31m225.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading gast-0.4.0-py3-none-any.whl (9.8 kB)\n","Downloading jax-0.4.30-py3-none-any.whl (2.0 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m246.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading keras-2.12.0-py2.py3-none-any.whl (1.7 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m237.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading protobuf-4.25.7-cp37-abi3-manylinux2014_x86_64.whl (294 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m294.6/294.6 kB\u001b[0m \u001b[31m186.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading tensorboard-2.12.3-py3-none-any.whl (5.6 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.6/5.6 MB\u001b[0m \u001b[31m219.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading tensorflow_estimator-2.12.0-py2.py3-none-any.whl (440 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m440.7/440.7 kB\u001b[0m \u001b[31m259.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading wrapt-1.14.1-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (78 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m78.4/78.4 kB\u001b[0m \u001b[31m179.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading google_auth_oauthlib-1.0.0-py2.py3-none-any.whl (18 kB)\n","Downloading jaxlib-0.4.30-cp311-cp311-manylinux2014_x86_64.whl (79.6 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m79.6/79.6 MB\u001b[0m \u001b[31m227.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hInstalling collected packages: wrapt, tensorflow-estimator, protobuf, numpy, keras, gast, pandas, jaxlib, google-auth-oauthlib, tensorboard, jax, tensorflow\n","  Attempting uninstall: wrapt\n","    Found existing installation: wrapt 1.17.2\n","    Uninstalling wrapt-1.17.2:\n","      Successfully uninstalled wrapt-1.17.2\n","  Attempting uninstall: protobuf\n","    Found existing installation: protobuf 5.29.4\n","    Uninstalling protobuf-5.29.4:\n","      Successfully uninstalled protobuf-5.29.4\n","  Attempting uninstall: keras\n","    Found existing installation: keras 3.8.0\n","    Uninstalling keras-3.8.0:\n","      Successfully uninstalled keras-3.8.0\n","  Attempting uninstall: gast\n","    Found existing installation: gast 0.6.0\n","    Uninstalling gast-0.6.0:\n","      Successfully uninstalled gast-0.6.0\n","  Attempting uninstall: jaxlib\n","    Found existing installation: jaxlib 0.5.1\n","    Uninstalling jaxlib-0.5.1:\n","      Successfully uninstalled jaxlib-0.5.1\n","  Attempting uninstall: google-auth-oauthlib\n","    Found existing installation: google-auth-oauthlib 1.2.2\n","    Uninstalling google-auth-oauthlib-1.2.2:\n","      Successfully uninstalled google-auth-oauthlib-1.2.2\n","  Attempting uninstall: tensorboard\n","    Found existing installation: tensorboard 2.18.0\n","    Uninstalling tensorboard-2.18.0:\n","      Successfully uninstalled tensorboard-2.18.0\n","  Attempting uninstall: jax\n","    Found existing installation: jax 0.5.2\n","    Uninstalling jax-0.5.2:\n","      Successfully uninstalled jax-0.5.2\n","\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","google-colab 1.0.0 requires pandas==2.2.2, but you have pandas 1.5.3 which is incompatible.\n","mizani 0.13.5 requires pandas>=2.2.0, but you have pandas 1.5.3 which is incompatible.\n","xarray 2025.3.1 requires numpy>=1.24, but you have numpy 1.23.5 which is incompatible.\n","xarray 2025.3.1 requires pandas>=2.1, but you have pandas 1.5.3 which is incompatible.\n","orbax-checkpoint 0.11.13 requires jax>=0.5.0, but you have jax 0.4.30 which is incompatible.\n","bigframes 2.4.0 requires numpy>=1.24.0, but you have numpy 1.23.5 which is incompatible.\n","tensorflow-decision-forests 1.11.0 requires tensorflow==2.18.0, but you have tensorflow 2.12.0 which is incompatible.\n","tf-keras 2.18.0 requires tensorflow<2.19,>=2.18, but you have tensorflow 2.12.0 which is incompatible.\n","blosc2 3.3.2 requires numpy>=1.26, but you have numpy 1.23.5 which is incompatible.\n","chex 0.1.89 requires numpy>=1.24.1, but you have numpy 1.23.5 which is incompatible.\n","dask-expr 1.1.21 requires pandas>=2, but you have pandas 1.5.3 which is incompatible.\n","treescope 0.1.9 requires numpy>=1.25.2, but you have numpy 1.23.5 which is incompatible.\n","scikit-image 0.25.2 requires numpy>=1.24, but you have numpy 1.23.5 which is incompatible.\n","ydf 0.11.0 requires protobuf<6.0.0,>=5.29.1, but you have protobuf 4.25.7 which is incompatible.\n","cudf-cu12 25.2.1 requires pandas<2.2.4dev0,>=2.0, but you have pandas 1.5.3 which is incompatible.\n","pymc 5.22.0 requires numpy>=1.25.0, but you have numpy 1.23.5 which is incompatible.\n","tensorflow-text 2.18.1 requires tensorflow<2.19,>=2.18.0, but you have tensorflow 2.12.0 which is incompatible.\n","dask-cudf-cu12 25.2.2 requires pandas<2.2.4dev0,>=2.0, but you have pandas 1.5.3 which is incompatible.\n","imbalanced-learn 0.13.0 requires numpy<3,>=1.24.3, but you have numpy 1.23.5 which is incompatible.\n","thinc 8.3.6 requires numpy<3.0.0,>=2.0.0, but you have numpy 1.23.5 which is incompatible.\n","albumentations 2.0.6 requires numpy>=1.24.4, but you have numpy 1.23.5 which is incompatible.\n","plotnine 0.14.5 requires pandas>=2.2.0, but you have pandas 1.5.3 which is incompatible.\n","flax 0.10.6 requires jax>=0.5.1, but you have jax 0.4.30 which is incompatible.\n","grpcio-status 1.71.0 requires protobuf<6.0dev,>=5.26.1, but you have protobuf 4.25.7 which is incompatible.\n","albucore 0.0.24 requires numpy>=1.24.4, but you have numpy 1.23.5 which is incompatible.\n","db-dtypes 1.4.3 requires numpy>=1.24.0, but you have numpy 1.23.5 which is incompatible.\u001b[0m\u001b[31m\n","\u001b[0mSuccessfully installed gast-0.4.0 google-auth-oauthlib-1.0.0 jax-0.4.30 jaxlib-0.4.30 keras-2.12.0 numpy-1.23.5 pandas-1.5.3 protobuf-4.25.7 tensorboard-2.12.3 tensorflow-2.12.0 tensorflow-estimator-2.12.0 wrapt-1.14.1\n"]},{"output_type":"display_data","data":{"application/vnd.colab-display-data+json":{"pip_warning":{"packages":["numpy"]},"id":"011228e017a540bcbb2cfa0e723db36a"}},"metadata":{}}],"source":["!pip uninstall -y numpy pandas tensorflow\n","!pip install --no-cache-dir tensorflow==2.12.0 numpy==1.23.5 pandas==1.5.3"]},{"cell_type":"markdown","source":["### 2. Importing Libraries\n","\n","Here, we will imports the necessary Python Libraries and Mount the Google Drive to access the model weights, label, and test images"],"metadata":{"id":"FwcD3iSBYMUJ"}},{"cell_type":"code","source":["import numpy as np\n","import pandas as pd\n","import tensorflow as tf\n","from tensorflow import keras\n","from tensorflow.keras.preprocessing import image\n","import os\n","import matplotlib.pyplot as plt\n","from google.colab import files\n","import io\n","import zipfile\n","from tqdm.notebook import tqdm\n","\n","from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":391},"id":"mV86h5TBMUwv","executionInfo":{"status":"error","timestamp":1748052331438,"user_tz":-480,"elapsed":112,"user":{"displayName":"Jay Yen Lim","userId":"02744417412835953839"}},"outputId":"9899e57c-83a5-4bed-f2d0-a50c773a5832"},"execution_count":2,"outputs":[{"output_type":"error","ename":"ValueError","evalue":"numpy.dtype size changed, may indicate binary incompatibility. Expected 96 from C header, got 88 from PyObject","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)","\u001b[0;32m<ipython-input-2-d1fe47aae259>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mpandas\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtensorflow\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpreprocessing\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mimage\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;31m# numpy compat\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mpandas\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompat\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mis_numpy_dev\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0m_is_numpy_dev\u001b[0m  \u001b[0;31m# pyright: ignore # noqa:F401\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/compat/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtyping\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mTYPE_CHECKING\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mpandas\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_typing\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m from pandas.compat.numpy import (\n\u001b[1;32m     19\u001b[0m     \u001b[0mis_numpy_dev\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/_typing.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    130\u001b[0m     \u001b[0mint\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    131\u001b[0m     \u001b[0mArrayLike\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 132\u001b[0;31m     \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mGenerator\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    133\u001b[0m     \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mBitGenerator\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    134\u001b[0m     \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mRandomState\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/numpy/__init__.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(attr)\u001b[0m\n\u001b[1;32m    335\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mabs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m2.0\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m1e-5\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    336\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mAssertionError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 337\u001b[0;31m         \u001b[0;32mexcept\u001b[0m \u001b[0mAssertionError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    338\u001b[0m             msg = (\"The current Numpy installation ({!r}) fails to \"\n\u001b[1;32m    339\u001b[0m                    \u001b[0;34m\"pass simple sanity checks. This can be caused for example \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/numpy/random/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    178\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    179\u001b[0m \u001b[0;31m# add these for module-freeze analysis (like PyInstaller)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 180\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0m_pickle\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    181\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0m_common\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    182\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0m_bounded_integers\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/numpy/random/_pickle.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mmtrand\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mRandomState\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0m_philox\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mPhilox\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0m_pcg64\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mPCG64\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mPCG64DXSM\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0m_sfc64\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mSFC64\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32mmtrand.pyx\u001b[0m in \u001b[0;36minit numpy.random.mtrand\u001b[0;34m()\u001b[0m\n","\u001b[0;31mValueError\u001b[0m: numpy.dtype size changed, may indicate binary incompatibility. Expected 96 from C header, got 88 from PyObject"]}]},{"cell_type":"markdown","source":["### 3. Upload Model & Labels.txt\n","\n","This is an example model file we attach. Do change this to your own model path.\n","\n","*Note:* This model is very bad at classifying images so you would need to train your own!"],"metadata":{"id":"64FMPpr9aj4U"}},{"cell_type":"code","source":["## CChange this to where your keras_model.h5 is\n","model_filename = '/content/drive/MyDrive/Public-Access/keras_model.h5'\n","model = keras.models.load_model(model_filename)\n","print(\"Model loaded successfully!\")\n"],"metadata":{"id":"ZddkdTizMWuh","executionInfo":{"status":"aborted","timestamp":1748052331579,"user_tz":-480,"elapsed":2,"user":{"displayName":"Jay Yen Lim","userId":"02744417412835953839"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["## Change this to where your labels.txt is\n","labels_filename = '/content/drive/MyDrive/Public-Access/labels.txt'\n","labels = {}\n","with open(labels_filename, 'r') as f:\n","    for line in f:\n","        if line.strip():\n","            idx, label = line.strip().split(' ', 1)\n","            labels[int(idx)] = label\n","\n","print(f\"Loaded {len(labels)} classes:\")\n","for idx, label in labels.items():\n","    print(f\"  {idx}: {label}\")"],"metadata":{"id":"OXIBn5lZNTId","executionInfo":{"status":"aborted","timestamp":1748052331622,"user_tz":-480,"elapsed":92915,"user":{"displayName":"Jay Yen Lim","userId":"02744417412835953839"}}},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### 4. Access Testing Directory\n","\n","Remember to make a shortcut to your own drive for that to work!"],"metadata":{"id":"zmbuqPz4a8Dr"}},{"cell_type":"code","source":["# Get list of test images\n","test_dir = '/content/drive/MyDrive/Public-Access/Testing'\n","test_images = []\n","for root, _, files in os.walk(test_dir):\n","    for file in files:\n","        if file.lower().endswith(('.png', '.jpg', '.jpeg')):\n","            test_images.append(os.path.join(root, file))\n","\n","test_images.sort()  # Sort to ensure consistent order\n","print(f\"Found {len(test_images)} test images\")"],"metadata":{"id":"AZgEEMWwR6AL","executionInfo":{"status":"aborted","timestamp":1748052331627,"user_tz":-480,"elapsed":92917,"user":{"displayName":"Jay Yen Lim","userId":"02744417412835953839"}}},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### 5. Running Predictions\n","\n","In this section, we process each image for model input (resize, normalize) and make prediction using the model label."],"metadata":{"id":"F0vug24DbN57"}},{"cell_type":"code","source":["predictions = []\n","input_shape = model.input_shape[1:3]\n","\n","for img_path in tqdm(test_images):\n","    try:\n","        # Preprocess the image\n","        img = image.load_img(img_path, target_size=input_shape)\n","        img_array = image.img_to_array(img)\n","        img_array = np.expand_dims(img_array, axis=0)\n","        img_array = img_array / 255.0  # Normalize to [0,1]\n","\n","        # Predict class probabilities\n","        pred_probs = model.predict(img_array, verbose=0)[0]  # shape: (n_classes,)\n","        predicted_class_idx = int(np.argmax(pred_probs))\n","\n","        # Get the label for the predicted class\n","        predicted_label = labels.get(predicted_class_idx, f\"Unknown ({predicted_class_idx})\")\n","\n","        # Store prediction result\n","        predictions.append({\n","            'image': os.path.basename(img_path),\n","            'predicted_class_index': predicted_class_idx,\n","            'predicted_label': predicted_label,\n","            'class_probabilities': pred_probs.tolist()  # convert to list for JSON-safe export\n","        })\n","\n","    except Exception as e:\n","        print(f\"Error processing {img_path}: {str(e)}\")\n","        predictions.append({\n","            'image': os.path.basename(img_path),\n","            'predicted_class_index': -1,\n","            'predicted_label': 'Error',\n","            'class_probabilities': []\n","        })"],"metadata":{"id":"JqF0JYYLU_f_","executionInfo":{"status":"aborted","timestamp":1748052331635,"user_tz":-480,"elapsed":92921,"user":{"displayName":"Jay Yen Lim","userId":"02744417412835953839"}}},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### 6. Creating Output\n","\n","In this section, you will convert the model's prediction results into a structured format and prepare it for submission.\n","\n","**Instructions:**\n","\n","1. Convert predictions to a DataFrame\n","Use pandas to store each image’s:\n","\n","- filename\n","- predicted class index\n","- predicted class label (match it back from labels.txt)\n","\n","\n","2. Save the results to a CSV file\n","Save the DataFrame using df.to_csv(\"predictions.csv\", index=False)."],"metadata":{"id":"Ng4sarwebX8I"}},{"cell_type":"code","source":["results_df = pd.DataFrame(predictions)\n","display(results_df)"],"metadata":{"id":"c5BGtR2sVK1V","executionInfo":{"status":"aborted","timestamp":1748052331644,"user_tz":-480,"elapsed":92924,"user":{"displayName":"Jay Yen Lim","userId":"02744417412835953839"}}},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### 7. Example Metrics Computation"],"metadata":{"id":"aslg3yzCPkOE"}},{"cell_type":"code","source":["from sklearn.metrics import (\n","    classification_report, accuracy_score,\n","    roc_auc_score, precision_recall_fscore_support\n",")\n","from sklearn.preprocessing import label_binarize\n","import numpy as np\n","\n","# True and predicted labels\n","true_labels = [1, 2, 5]  # Adjust this list to match your full test set\n","results_df['true_class_index'] = true_labels\n","y_true = results_df['true_class_index'].astype(int).values\n","y_pred = results_df['predicted_class_index'].astype(int).values\n","y_probs = np.array(results_df['class_probabilities'].tolist())\n","\n","## Quick fix for ROC Curve as I only have 3 classes here (DO NOT NEED THIS IF YOU HAVE 8 CLASSES IN YOUR TEST SET)\n","FULL_NUM_CLASSES = 8  # total number of possible classes\n","\n","# Pad probability vectors to length 8\n","def pad_probs(probs, target_len=FULL_NUM_CLASSES):\n","    padded = np.zeros(target_len)\n","    padded[:len(probs)] = probs  # assumes probs are in order (class 0, 1, 2, ...)\n","    return padded\n","\n","# Apply padding\n","y_probs_padded = np.array([pad_probs(p, FULL_NUM_CLASSES) for p in results_df['class_probabilities']])\n","\n","# Update your DataFrame or use directly in metrics\n","y_probs = y_probs_padded\n"],"metadata":{"id":"qr6a67piPmhi","executionInfo":{"status":"aborted","timestamp":1748052331654,"user_tz":-480,"elapsed":92932,"user":{"displayName":"Jay Yen Lim","userId":"02744417412835953839"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Number of classes\n","n_classes = FULL_NUM_CLASSES\n","class_names = list(range(FULL_NUM_CLASSES))\n","\n","# Accuracy\n","acc = accuracy_score(y_true, y_pred)\n","print(f\"\\n✅ Accuracy: {acc:.4f}\")\n","\n","# Precision, Recall, F1 per class & macro\n","prec, rec, f1, _ = precision_recall_fscore_support(y_true, y_pred, labels=class_names, average=None)\n","macro_prec, macro_rec, macro_f1, _ = precision_recall_fscore_support(y_true, y_pred, average='macro')\n","\n","print(\"\\n📊 Per-class metrics:\")\n","for i, cls in enumerate(class_names):\n","    print(f\"Class {cls}: Precision={prec[i]:.4f}, Recall={rec[i]:.4f}, F1={f1[i]:.4f}\")\n","\n","print(f\"\\n📦 Macro Precision: {macro_prec:.4f}, Macro Recall: {macro_rec:.4f}, Macro F1: {macro_f1:.4f}\")\n","\n","# ROC AUC (requires binarized labels)\n","y_true_bin = label_binarize(y_true, classes=class_names)\n","\n","# ROC AUC per class and macro\n","try:\n","    auc_per_class = roc_auc_score(y_true_bin, y_probs, average=None, multi_class='ovr')\n","    auc_macro = roc_auc_score(y_true_bin, y_probs, average='macro', multi_class='ovr')\n","\n","    print(\"\\n🎯 ROC AUC per class:\")\n","    for i, cls in enumerate(class_names):\n","        print(f\"Class {cls}: AUC = {auc_per_class[i]:.4f}\")\n","\n","    print(f\"\\n🌐 Macro ROC AUC: {auc_macro:.4f}\")\n","\n","except Exception as e:\n","    print(f\"⚠️ ROC AUC could not be computed: {e}\")\n"],"metadata":{"id":"crXZ4eRxPr1u","executionInfo":{"status":"aborted","timestamp":1748052331662,"user_tz":-480,"elapsed":92936,"user":{"displayName":"Jay Yen Lim","userId":"02744417412835953839"}}},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## 🔍 What’s Happening?\n","\n","1. **Per-Class Metrics**\n","   - Only class **5** was predicted correctly.\n","   - All other classes had **no true labels** and/or **no predicted labels**, hence precision, recall, and F1 are `0.0000`.\n","   - That’s why macro scores are low (`0.2500`) — averaging over all 8 classes.\n","\n","2. **ROC AUC**\n","   - Only classes with **at least one positive and one negative** sample can have an AUC.\n","   - Classes like **0, 3, 4, 6, 7** were **never in `y_true`**, so AUC = `nan`.\n","   - `roc_auc_score` emits warnings because for those classes, it’s mathematically **undefined**.\n","\n","3. **Macro ROC AUC**\n","   - If *any* class has AUC = `nan`, then the macro average becomes `nan` too.\n","   - This is why your `🌐 Macro ROC AUC: nan`.\n","\n"],"metadata":{"id":"PFbFNfukRJCU"}},{"cell_type":"code","source":[],"metadata":{"id":"svzOEViVRJmc","executionInfo":{"status":"aborted","timestamp":1748052331676,"user_tz":-480,"elapsed":92949,"user":{"displayName":"Jay Yen Lim","userId":"02744417412835953839"}}},"execution_count":null,"outputs":[]}]}